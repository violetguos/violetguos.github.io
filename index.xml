<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Y Violet Guo on Y Violet Guo</title>
    <link>https://violetguos.github.io/</link>
    <description>Recent content in Y Violet Guo on Y Violet Guo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>AccentDL</title>
      <link>https://violetguos.github.io/project/accentdl/</link>
      <pubDate>Sat, 12 Jan 2019 19:38:20 -0500</pubDate>
      
      <guid>https://violetguos.github.io/project/accentdl/</guid>
      <description>&lt;p&gt;The task of classifying the accent of recorded speech has generally been approached with traditional SVM or UBM-GMM methods (Omar and Pelecanos, 2010; Ge, 2015). However, modern deep learning methods yield the potential to dramatically increase performance. In our report, we train several varieties of Recurrent and Convolutional Neural Networks on three types of features (MFCC, formant, and raw spectrogram) extracted from North American and British English speech recordings in order to predict the accent of the speaker. All deep learning methods examined surpass non-deep baselines, and the approach yielding the best performance was the MFCC-RNN, shortly followed by the Spec-CNN.&lt;/p&gt;

&lt;p&gt;The MFCC-RNN performs best on our accent classification task, likely due to its sufficiently complex and salient features and its ability to take contextual information into account, and its performance is shortly followed by that of the the Spec-CNN (which may outperform the MFCC-RNN given more data and more computational power). The Formant-RNN performs worst of the three, likely due to the excessively low amount of information present in its features.&lt;/p&gt;

&lt;p&gt;A straightforward next step in evaluating these network architectures and feature choices would be to extend them beyond binary classification, including data from many varieties of English. This would allow a more direct comparison with works such as Chu, Lai, and Le (2017), which was unable to classify multiple varieties of accented English well using an MFCC approach.&lt;/p&gt;

&lt;p&gt;Further future work might include expansion on the Spec-CNN, since current research continues to look into new types of convolution to curate filters for audio signals. One successful application of CNNs with raw audio involves using parametrized sinc functions in the convolution layer instead of a traditional convolution, as in SincNet developed by Ravanelli and Bengio (2018). Dilated convolutions have also been shown to be useful for accent correction and audio generation, since they allow the receptive fields to grow longer in a cheaper way than do LSTMs or other RNNs (Oord et al., 2016).&lt;/p&gt;

&lt;p&gt;Though it underperformed in this work, the above-baseline performance of the Formant-RNN also holds potential due to the easy interpretability of its features. Future work might construct a mapping from the features picked out as important by the network back to their original timestamp, which could be the basis of an accent correction system that delivers feedback to a user about which portions of their speech need adjustment in order to imitate a certain accent. This is especially applicable to the Formant-RNN since there is a well-understood relationship between the configuration of the mouth and the first two formants of a vowel. Such a system could provide practical instructions to the user (i.e. to raise or lower the tongue, round the lips, etc.) and could have applications in language learning or speech therapy tools.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pacman with AI</title>
      <link>https://violetguos.github.io/project/pacmanai/</link>
      <pubDate>Sat, 12 Jan 2019 19:22:15 -0500</pubDate>
      
      <guid>https://violetguos.github.io/project/pacmanai/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Speaker Accent Classification with Deep Learning</title>
      <link>https://violetguos.github.io/post/accentdl/</link>
      <pubDate>Sat, 12 Jan 2019 17:04:01 -0500</pubDate>
      
      <guid>https://violetguos.github.io/post/accentdl/</guid>
      <description>&lt;p&gt;The task of classifying the accent of recorded speech has generally been approached with traditional SVM or UBM-GMM methods (Omar and Pelecanos, 2010; Ge, 2015). However, modern deep learning methods yield the potential to dramatically increase performance. In our report, we train several varieties of Recurrent and Convolutional Neural Networks on three types of features (MFCC, formant, and raw spectrogram) extracted from North American and British English speech recordings in order to predict the accent of the speaker. All deep learning methods examined surpass non-deep baselines, and the approach yielding the best performance was the MFCC-RNN, shortly followed by the Spec-CNN.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mfcc-rnn-arch.png&#34; alt=&#34;mfcc&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The MFCC-RNN performs best on our accent classification task, likely due to its sufficiently complex and salient features and its ability to take contextual information into account, and its performance is shortly followed by that of the the Spec-CNN (which may outperform the MFCC-RNN given more data and more computational power). The Formant-RNN performs worst of the three, likely due to the excessively low amount of information present in its features.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mfcc-rnn.png&#34; alt=&#34;mfcc&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A straightforward next step in evaluating these network architectures and feature choices would be to extend them beyond binary classification, including data from many varieties of English. This would allow a more direct comparison with works such as Chu, Lai, and Le (2017), which was unable to classify multiple varieties of accented English well using an MFCC approach.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;spec-cnn-arch.png&#34; alt=&#34;cnn&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Further future work might include expansion on the Spec-CNN, since current research continues to look into new types of convolution to curate filters for audio signals. One successful application of CNNs with raw audio involves using parametrized sinc functions in the convolution layer instead of a traditional convolution, as in SincNet developed by Ravanelli and Bengio (2018). Dilated convolutions have also been shown to be useful for accent correction and audio generation, since they allow the receptive fields to grow longer in a cheaper way than do LSTMs or other RNNs (Oord et al., 2016).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;formant-rnn-arch.png&#34; alt=&#34;formant&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Though it underperformed in this work, the above-baseline performance of the Formant-RNN also holds potential due to the easy interpretability of its features. Future work might construct a mapping from the features picked out as important by the network back to their original timestamp, which could be the basis of an accent correction system that delivers feedback to a user about which portions of their speech need adjustment in order to imitate a certain accent. This is especially applicable to the Formant-RNN since there is a well-understood relationship between the configuration of the mouth and the first two formants of a vowel. Such a system could provide practical instructions to the user (i.e. to raise or lower the tongue, round the lips, etc.) and could have applications in language learning or speech therapy tools.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;formants_plt.png&#34; alt=&#34;formant&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Roulette</title>
      <link>https://violetguos.github.io/project/roulette/</link>
      <pubDate>Sat, 12 Jan 2019 17:00:09 -0500</pubDate>
      
      <guid>https://violetguos.github.io/project/roulette/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cpu</title>
      <link>https://violetguos.github.io/project/cpu/</link>
      <pubDate>Sat, 12 Jan 2019 17:00:02 -0500</pubDate>
      
      <guid>https://violetguos.github.io/project/cpu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Security Project Github Repo</title>
      <link>https://violetguos.github.io/project/security/</link>
      <pubDate>Sat, 12 Jan 2019 15:47:52 -0500</pubDate>
      
      <guid>https://violetguos.github.io/project/security/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Security Project: Exploiting OS using C and Assembly</title>
      <link>https://violetguos.github.io/post/security/</link>
      <pubDate>Sun, 12 Nov 2017 16:10:39 -0500</pubDate>
      
      <guid>https://violetguos.github.io/post/security/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Cybersecurity is a branch of study in computer system and algorithm that aims to provide security to data and programs. The two types of work done are
1. Improve computer system to shield users from attackers
2. Encrypt data so that when the device is compromised, the attacker cannot decrypt user data&lt;/p&gt;

&lt;p&gt;The course project is also designed to address these two objective
1. Given a vulnerable system, implement code to attack the system
2. Program effective encryption
I will provide a detailed explanation for both techniques&lt;/p&gt;

&lt;h2 id=&#34;what-is-code-injection&#34;&gt;What is code injection?&lt;/h2&gt;

&lt;p&gt;Think about how many times a webpage has asked for your input: username, password, your comment on your friend&amp;rsquo;s profile picture. Your input will go into the webpage&amp;rsquo;s server. When your friend&amp;rsquo;s friend read your comment, it will be retrieved from the server, and loaded on their devices. What if your comment is not written in human language? What if it is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;\xeb\x2a\x5e\x89\x76\x08\xc6\x46\x07\x00\xc7\x46\x0c\x00\x00\x00&amp;quot;
&amp;quot;\x00\xb8\x0b\x00\x00\x00\x89\xf3\x8d\x4e\x08\x8d\x56\x0c\xcd\x80&amp;quot;
&amp;quot;\xb8\x01\x00\x00\x00\xbb\x00\x00\x00\x00\xcd\x80\xe8\xd1\xff\xff&amp;quot;
&amp;quot;\xff\x2f\x62\x69\x6e\x2f\x73\x68\x00\x89\xec\x5d\xc3&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Don&amp;rsquo;t worry, as you are reading this post, your device is not compromised by this code. It has to be loaded into operating system kernel memory address in order to be exploited.&lt;/p&gt;

&lt;p&gt;However, if it is loaded into operating system [https//en.wikipedia.org/wiki/Kernel_(operating_system)]kernel memory address, this assembly code (Ron&amp;rsquo;s Code, the author Ron is the R in CLRS algorithm book) can get administrator access to everything on your OS!&lt;/p&gt;

&lt;h2 id=&#34;what-is-cryptography&#34;&gt;What is cryptography?&lt;/h2&gt;

&lt;p&gt;Cryptography allows users to apply a non-linear transformation on their data. User can encrypt their data with an 128-bit key. Unlike conventional passwords, which is generated by users, is short, and is simple to crack. Many passwords contain birthday, user&amp;rsquo;s initials, important dates and places, etc. The key is random.&lt;/p&gt;

&lt;p&gt;If you are interested in math, skip this note.&lt;/p&gt;

&lt;p&gt;Note: random here is strictly defined as pseudo-random within a space of infinite dimension. In this case, the dimension is defined by how many bits the encryption key has.&lt;/p&gt;

&lt;p&gt;Because cryptography is non-linear and is based on discrete log operations, it take 2^128 trials to crack a key, which is equivalent to 5.4 *10^18 years. For more math about cryptography, please refer to &lt;a href=&#34;http://www-inst.eecs.berkeley.edu/~cs161/sp18/notes/3.4.signatures.pdf&#34; target=&#34;_blank&#34;&gt;http://www-inst.eecs.berkeley.edu/~cs161/sp18/notes/3.4.signatures.pdf&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;my-result&#34;&gt;My Result&lt;/h2&gt;

&lt;p&gt;For objective 1:
- Implemented C language memory exploit to inject code in vulnerable program
- Implement HTML, Javascript, and SQL attack to program &amp;ldquo;phishing&amp;rdquo; on vulnerable  webpages&lt;/p&gt;

&lt;p&gt;For objective 2:
- Implemented an encrypted communication network socket in OpenSSL in C
- Verified encryption using a cryptographic hash (HMAC and SHA1) in C&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pacman with AI</title>
      <link>https://violetguos.github.io/post/pacmanai/</link>
      <pubDate>Wed, 01 Nov 2017 07:02:56 -0500</pubDate>
      
      <guid>https://violetguos.github.io/post/pacmanai/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The classic algorithm for game playing is to program computers to &amp;ldquo;think&amp;rdquo; like a chess master. However, computers are not good at wholistic reasoning which often involves some philosophical ideas about chess. Instead, artificial intelligence programs a computer to search for the best move out of all moves. Right away, you may think that it is exhaustive search where you look for all the combinations of possible solutions. This is where artificial intelligence comes in and improves that search with heuristics and parallel processing to selectively search for the best move.&lt;/p&gt;

&lt;h2 id=&#34;algorithms-used&#34;&gt;Algorithms Used&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Programmed path finding algorithms, game tree with alpha-beta pruning, and Hidden
Markov Model in Berkeley Pacman framework&lt;/li&gt;
&lt;li&gt;Programmed an abstract constrain satisfaction problem class using forward checking in Python to solve Sudoku and n-queens&lt;/li&gt;
&lt;li&gt;Achieved a grade of 94% in this course(CSC384)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Android app to reduce clinic wait time</title>
      <link>https://violetguos.github.io/post/andriod/</link>
      <pubDate>Sun, 12 Jun 2016 16:57:28 -0500</pubDate>
      
      <guid>https://violetguos.github.io/post/andriod/</guid>
      <description>

&lt;p&gt;This is a hackathon project developed outside of school.&lt;/p&gt;

&lt;h2 id=&#34;problem&#34;&gt;Problem&lt;/h2&gt;

&lt;p&gt;Far too many Canadians facing long wait times for health services experience frustration and wonder if our healthcare system is broken. Literature points to a negative impact of wait time on patients&amp;rsquo; perceptions of health care quality, satisfaction and likeability, patients&amp;rsquo; subsequent behavior, and likelihood of recommendations and repeat visits.&lt;/p&gt;

&lt;h2 id=&#34;how-it-works&#34;&gt;How it works&lt;/h2&gt;

&lt;p&gt;Patients with our app, who have booked an appointment can check-in remotely 30 min before their appointment, if they’re close enough to the medical clinic. Alternatively, a receptionist can check patients in. However, patients don’t need to wait in the clinic for hours on end if the queue time is long, but can instead go about their day. When they’re next in line to be seen, patients would be notified to go back to the clinic.&lt;/p&gt;

&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;

&lt;p&gt;Angular.js, Express, Node.js, MongoDB, Amazon EC2, Amazon SES, Java, Android&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An Android app that aims to reduce patient waiting time built at Angel Hacks.&lt;/li&gt;
&lt;li&gt;Built with a web platform for hospital staff and a mobile app for patients&lt;/li&gt;
&lt;li&gt;Developed a function to calculate distance and configured user interface&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;clinic4.png&#34; alt=&#34;login&#34; /&gt;
&lt;img src=&#34;clinic1.png&#34; alt=&#34;clinics&#34; /&gt;
&lt;img src=&#34;clinic5.png&#34; alt=&#34;wait&#34; /&gt;
&lt;img src=&#34;clinic3.png&#34; alt=&#34;check-in&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Program MIPS instruction in Verilog</title>
      <link>https://violetguos.github.io/post/cpu/</link>
      <pubDate>Sat, 02 Apr 2016 06:28:35 -0500</pubDate>
      
      <guid>https://violetguos.github.io/post/cpu/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this project, I have built a multi-cycle processor&amp;rsquo;s instruction set from scratch.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;processor.jpg&#34; alt=&#34;draft&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Programmed a multicycle processor in Verilog on a Altera DE-1 FPGA&lt;/li&gt;
&lt;li&gt;Configured a new Assembly language instruction set with Verilog&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;procses.png&#34; alt=&#34;final&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;lessons-learned&#34;&gt;Lessons Learned&lt;/h2&gt;

&lt;p&gt;In processor or hardware design, unlike computer software, there is no room for uncertainty. For example, a software engineer may put a button in a not so convenient place for no good reason, but it does not hinder the functionality of the app, just harder to navigate. In hardware, everything must be precise. A small error (0 vs 1) results in something completely different. As you can see below, we have tested our design on paper, drawing out each and every cycle of execution. Everything was planned beforehand.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Roulette on FPGA</title>
      <link>https://violetguos.github.io/post/roulette/</link>
      <pubDate>Sat, 02 Apr 2016 01:29:17 -0500</pubDate>
      
      <guid>https://violetguos.github.io/post/roulette/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This project was built in the same course as the multi-cycle CPU! As the reader can see, low level hardware can be fun. The two projects share similar principles, but this project has additional displays, such as a computer screen, a speaker for audio output, and we made the roulette as pretty as we could. They all run on the same hardware chip(field programmable gate array, FPGA).&lt;/p&gt;

&lt;h2 id=&#34;technical-details&#34;&gt;Technical Details&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Built a roulette game with PS/2 keyboard, audio output, motor, lego controller, and Altera FPGA&lt;/li&gt;
&lt;li&gt;Implemented linear feedback shift register in Assembly and C to randomize motor speed and spin time&lt;/li&gt;
&lt;li&gt;Interfaced keyboard input to prompt user’s bet and display on VGA output with JTAG UART, JPIO ports&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;lessons-learned&#34;&gt;Lessons Learned&lt;/h2&gt;

&lt;p&gt;User interface (the screen display, music, and the roulette) makes a difference
Creativity matters: engineers should not only focus on the technical details&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;roulette.jpg&#34; alt=&#34;roulette&#34; /&gt;
Note: this is not my final version. Unfortunately the finished product and a recorded video demo were lost.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
