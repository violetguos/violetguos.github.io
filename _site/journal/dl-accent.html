<!doctype html>
<html>

<head>

  <title>
    
      Deep learning project 1 | Y. Violet Guo
    
  </title>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="/assets/css/syntax.css">
  <!-- Use Atom -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:5005/feed.xml" title="Y. Violet Guo" />
  <!-- Use RSS-2.0 -->
  <!--<link href="/rss-feed.xml" type="application/rss+xml" rel="alternate" title="Y. Violet Guo | my personal website"/>
  //-->

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Code+Pro">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Quattrocento+Sans">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        }
      });
  </script>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>


  <!-- Use Jekyll SEO plugin -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Deep learning project 1 | Y. Violet Guo</title>
<meta name="generator" content="Jekyll v3.6.3" />
<meta property="og:title" content="Deep learning project 1" />
<meta name="author" content="Violet" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The task of classifying the accent of recorded speech has generally been approached with traditional SVM or UBM-GMM methods (Omar and Pelecanos, 2010; Ge, 2015). However, modern deep learning methods yield the potential to dramatically increase performance. In our report, we train several varieties of Recurrent and Convolutional Neural Networks on three types of features (MFCC, formant, and raw spectrogram) extracted from North American and British English speech recordings in order to predict the accent of the speaker. All deep learning methods examined surpass non-deep baselines, and the approach yielding the best performance was the MFCC-RNN, shortly followed by the Spec-CNN." />
<meta property="og:description" content="The task of classifying the accent of recorded speech has generally been approached with traditional SVM or UBM-GMM methods (Omar and Pelecanos, 2010; Ge, 2015). However, modern deep learning methods yield the potential to dramatically increase performance. In our report, we train several varieties of Recurrent and Convolutional Neural Networks on three types of features (MFCC, formant, and raw spectrogram) extracted from North American and British English speech recordings in order to predict the accent of the speaker. All deep learning methods examined surpass non-deep baselines, and the approach yielding the best performance was the MFCC-RNN, shortly followed by the Spec-CNN." />
<link rel="canonical" href="http://localhost:5005/journal/dl-accent.html" />
<meta property="og:url" content="http://localhost:5005/journal/dl-accent.html" />
<meta property="og:site_name" content="Y. Violet Guo" />
<meta property="og:image" content="http://localhost:5005/projects/mfcc-rnn-arch.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-01T00:00:00-04:00" />
<script type="application/ld+json">
{"url":"http://localhost:5005/journal/dl-accent.html","headline":"Deep learning project 1","dateModified":"2019-01-01T00:00:00-04:00","datePublished":"2019-01-01T00:00:00-04:00","image":"http://localhost:5005/projects/mfcc-rnn-arch.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:5005/journal/dl-accent.html"},"author":{"@type":"Person","name":"Violet"},"description":"The task of classifying the accent of recorded speech has generally been approached with traditional SVM or UBM-GMM methods (Omar and Pelecanos, 2010; Ge, 2015). However, modern deep learning methods yield the potential to dramatically increase performance. In our report, we train several varieties of Recurrent and Convolutional Neural Networks on three types of features (MFCC, formant, and raw spectrogram) extracted from North American and British English speech recordings in order to predict the accent of the speaker. All deep learning methods examined surpass non-deep baselines, and the approach yielding the best performance was the MFCC-RNN, shortly followed by the Spec-CNN.","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->


</head>


<body>

  <div class="container">
    <header class="masthead">
  <h3 class="masthead-title">
    <a href="/">Y. Violet Guo</a>
    <small class="masthead-subtitle">my personal website</small>
    <div class="menu">
  <nav class="menu-content">
    
      <a href="/menu/about.html">About</a>
    
      <a href="/menu/writing.html">Writing</a>
    
      <a href="/menu/contact.html">Contact</a>
    
  </nav>
  <nav class="social-icons">
    
  
  
    <a href="https://www.github.com/violetguos" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/YVioletGuo" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="http://www.linkedin.com/in/yvioletguo/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:violetyueguo@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  </nav>
</div>

  </h3>
</header>


    <div class="post-container">
      <h1>
  Deep learning project 1
</h1>


  <img src="/assets/img/projects/mfcc-rnn-arch.png">


<p>The task of classifying the accent of recorded speech has generally been approached with traditional SVM or UBM-GMM methods (Omar and Pelecanos, 2010; Ge, 2015). However, modern deep learning methods yield the potential to dramatically increase performance. In our report, we train several varieties of Recurrent and Convolutional Neural Networks on three types of features (MFCC, formant, and raw spectrogram) extracted from North American and British English speech recordings in order to predict the accent of the speaker. All deep learning methods examined surpass non-deep baselines, and the approach yielding the best performance was the MFCC-RNN, shortly followed by the Spec-CNN.</p>

<div class="image-container">
  <a href="" target="_blank">
    <img src="/assets/img/projects/mfcc-rnn-arch.png" alt="Avatar" class="image" />
    <div class="overlay">
      <div class="text">
        
          View Demo <i class="fa fa-arrow-right" aria-hidden="true"></i>
        
      </div>
    </div>
  </a>
</div>

<p>The MFCC-RNN performs best on our accent classification task, likely due to its sufficiently complex and salient features and its ability to take contextual information into account, and its performance is shortly followed by that of the the Spec-CNN (which may outperform the MFCC-RNN given more data and more computational power). The Formant-RNN performs worst of the three, likely due to the excessively low amount of information present in its features.</p>

<p><a href="assets/img/projects/mfcc-rnn.png">mfcc</a></p>

<p>A straightforward next step in evaluating these network architectures and feature choices would be to extend them beyond binary classification, including data from many varieties of English. This would allow a more direct comparison with works such as Chu, Lai, and Le (2017), which was unable to classify multiple varieties of accented English well using an MFCC approach.</p>

<p><a href="assets/img/projects/spec-cnn-arch.png">cnn</a></p>

<p>Further future work might include expansion on the Spec-CNN, since current research continues to look into new types of convolution to curate filters for audio signals. One successful application of CNNs with raw audio involves using parametrized sinc functions in the convolution layer instead of a traditional convolution, as in SincNet developed by Ravanelli and Bengio (2018). Dilated convolutions have also been shown to be useful for accent correction and audio generation, since they allow the receptive fields to grow longer in a cheaper way than do LSTMs or other RNNs (Oord et al., 2016).</p>

<p><a href="assets/img/projects/formant-rnn-arch.png">formant</a></p>

<p>Though it underperformed in this work, the above-baseline performance of the Formant-RNN also holds potential due to the easy interpretability of its features. Future work might construct a mapping from the features picked out as important by the network back to their original timestamp, which could be the basis of an accent correction system that delivers feedback to a user about which portions of their speech need adjustment in order to imitate a certain accent. This is especially applicable to the Formant-RNN since there is a well-understood relationship between the configuration of the mouth and the first two formants of a vowel. Such a system could provide practical instructions to the user (i.e. to raise or lower the tongue, round the lips, etc.) and could have applications in language learning or speech therapy tools.</p>

<p><img src="assets/img/projects/formants_plt.png" alt="formant" /></p>


<span class="post-date">
  Written on
  
  January
  1st
    ,
  2019
  by
  
    Violet
  
</span>

<div class="post-date">Feel free to share!</div>
  <div class="sharing-icons">
    <a href="https://twitter.com/intent/tweet?text=Deep learning project 1&amp;url=/journal/dl-accent.html" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
    <a href="https://www.facebook.com/sharer/sharer.php?u=/journal/dl-accent.html&amp;title=Deep learning project 1" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a>
  </div>
</div>


<div class="related">
  <h1 >You may also enjoy:</h1>
  
  <ul class="related-posts">
    
      
        
        
      
        
          <li>
            <h3>
              <a href="/journal/welcome-to-lagrange.html">
                Welcome to Lagrange!
                <!--<img src="http://localhost:5005/images/">-->
                <!--<small>January 1, 2016</small>-->
              </a>
            </h3>
          </li>
          
        
      
        
          <li>
            <h3>
              <a href="/journal/getting-started.html">
                Getting Started
                <!--<img src="http://localhost:5005/images/">-->
                <!--<small>October 10, 2015</small>-->
              </a>
            </h3>
          </li>
          
        
      
    
      
        
        
      
        
        
      
        
        
      
    
  </ul>
</div>




    </div>

    <footer class="footer">
  
  
  
    <a href="https://www.github.com/violetguos" target="_blank"><i class="fa fa-github" aria-hidden="true"></i></a>
  

  
  
    <a href="https://twitter.com/YVioletGuo" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a>
  

  
  
    <a href="http://www.linkedin.com/in/yvioletguo/" target="_blank"><i class="fa fa-linkedin" aria-hidden="true"></i></a>
  

  
  
    <a href="mailto:violetyueguo@gmail.com" target="_blank"><i class="fa fa-envelope" aria-hidden="true"></i></a>
  

  
  
    <a href="/feed.xml"><i class="fa fa-rss-square" aria-hidden="true"></i></a>
  

  <div class="post-date"><a href="/menu/about.html">Y. Violet Guo | my personal website sourced from Paul Le</a></div>
</footer>


  </div>

</body>
</html>
