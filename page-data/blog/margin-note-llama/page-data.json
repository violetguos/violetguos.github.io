{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/margin-note-llama/","result":{"data":{"avatar":null,"site":{"siteMetadata":{"title":"Violet Guo","siteUrl":"https://violetguos.github.io","author":{"name":"Violet Guo","info":"machine learning, swe"}}},"markdownRemark":{"id":"8885d531-3507-577f-8c18-a6c8c7036b3d","excerpt":"I recently read the LLAMA paper from an industry pracitioner’s point of view.\nThe quoted sections are exerepts from the original paper. The following comments…","html":"<p>I recently read the LLAMA paper from an industry pracitioner’s point of view.\nThe quoted sections are exerepts from the original paper. The following comments, questions, and observations are based on my margin notes.</p>\n<blockquote>\n<p>However, recent work from Hoffmann et al. (2022) shows that, for a given compute budget, the best performances are not achieved by the largest mod- els, but by smaller models trained on more data.\nThe objective of the scaling laws from Hoff- mann et al. (2022) is to determine how to best scale the dataset and model sizes for a particular training compute budget. However, this objective disregards the inference budget, which becomes critical when serving a language model at scale.</p>\n</blockquote>\n<p>very insghtful remark with practical implications in model serving for most user facing products.</p>\n<blockquote>\n<p>2.1 Pretraining Data</p>\n</blockquote>\n<p>Meta preprocessed text data with basic non DL models, such as</p>\n<ul>\n<li>CCNET pipeline</li>\n<li>fast text linear classifeir</li>\n</ul>\n<blockquote>\n<p>The preprocessing of C4 also contains deduplication and language identifi- cation steps: the main difference with CCNet is the quality filtering, which mostly relies on heuris- tics such as presence of punctuation marks or the number of words and sentences in a webpage</p>\n</blockquote>\n<p>I wonder if they did any hyper parameter tuning, e.g. empirical observation of different heuristics used instead of just presence of puncation.</p>\n<blockquote>\n<p>Github\nwe filtered low quality files with heuristics based on the line length or proportion of alphanumeric characters, and removed boilerplate, such as headers, with reg- ular expressions.</p>\n</blockquote>\n<p>How did they decide whcih regex to use?</p>\n<blockquote>\n<p>arXiv. We process arXiv Latex files to add scientific data to our dataset. Following Lewkowycz et al. (2022), we removed everything before the first section, as well as the bibliography. We also removed the comments from the .tex files, and inline-expanded definitions and macros written by users to increase consistency across papers.</p>\n</blockquote>\n<p>In Lwekowycz et al, they explianed this preprocessing in more detail. In a typical NeurIps paper, the format is set by the conference. It roughyly follows the following structure.</p>\n<pre class=\"grvsc-container quiet-light grvsc-ps-tuw09S\" data-language=\"\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">\\userpackage{some_package}</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\some_customized_color_for_fancy_plots</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\author_list{some names}</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\title{impressive acronym for the model}</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">% some comment</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">% or a lot of comments</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\begin{abstract}</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">usually we only read this</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\end{abstract}</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\section{One big section}</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">continues until conclusion</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\include{compiled bibliography}</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">\\appendex{some extra info}</span></span></code></pre>\n<p>Lwekowycz et al removed the bibliography as well as everything before the first <code>\\section</code>. I am curious why they chose to exclude the abstract. Their work intended to train language models to perform on mathemtical text. Would including the abstracts that summarize the overall research and mathematical princples enhance the model’s peroformance on mathematical reasoning?</p>\n<p>No explanation was given by LLAMA authors or Lewkowycz et al.</p>\n<blockquote>\n<p>Pre-normalization [GPT3]. To improve the training stability, we normalize the input of each transformer sub-layer, instead of normalizing the output. We use the RMSNorm normalizing func- tion, introduced by Zhang and Sennrich (2019).</p>\n</blockquote>\n<p>Did they run into numerical stability issues in the input layer even before the activitions? Or was it just done to boost performance? What about other normalization methods?</p>\n<blockquote>\n<p>This imple- mentation, available in the xformers library,2 is inspired by Rabe and Staats (2021) and uses the backward from Dao et al. (2022). This is achieved by not storing the attention weights and not com- puting the key/query scores that are masked due to the causal nature of the language modeling task.</p>\n</blockquote>\n<p>For masked tokens, they simply skipped the computation.</p>\n<blockquote>\n<p>To further improve training efficiency, we re- duced the amount of activations that are recom- puted during the backward pass with checkpoint- ing. More precisely, we save the activations that are expensive to compute, such as the outputs of linear layers. This is achieved by manually imple- menting the backward function for the transformer layers, instead of relying on the PyTorch autograd.</p>\n</blockquote>\n<p>The authors played with pytorch’s autograd. My team did this when we tried to train a Wasserstein GAN. In any neural network, normally PyTorch builds a graph based on all the matrix transoformations you define, and does all the matrix calculus for you automatically. When you disable autograd, from that layer going backward, you are on your own. You need to</p>\n<ol>\n<li>derive the matrix calculus needed for backpropagation</li>\n<li>program it</li>\n<li>ensure the matrix dimensions are correct</li>\n<li>enhance the performance, address issues such as OOM and parallelism</li>\n</ol>\n<p>Ideally, the authors shouldn’t skim over this section, as it is extremely hard. Many folks in industry would benefit greatly if they could be more candid and discuss things they’ve tried, and what worked vs what didn’t work.</p>\n<p>Fortunately, Meta researchers were generous and provided a link to their repo. This <a href=\"https://github.com/facebookresearch/xformers/blob/6e1718b4af7e80087b9a247a6cd100b0cd2be339/xformers/components/reversible.py#L87\">customzied back propagation function</a> looks like their customized gradient calculation in the backpropagation.</p>\n<pre class=\"grvsc-container quiet-light grvsc-ps-tuw09S\" data-language=\"python\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">    </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-11\">def</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-9 grvsc-tZ0ymb-b grvsc-tuw09S-10\">backward_pass</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">(</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">self</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">y</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">:</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">Tensor</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">dy</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">:</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">Tensor</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">f_args</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">{},</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">g_args</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">{}</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">    </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">):</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">  </span><span class=\"grvsc-tZ0ymb-3 grvsc-tZ0ymb-i grvsc-tuw09S-4\"># pragma: no cover  # this is covered, but called directly from C++</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        y1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> y2 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">chunk</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">(</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">y</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-3\">2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-13\">self</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">split_dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">del</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> y</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        dy1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dy2 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">chunk</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">(</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">dy</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-3\">2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-13\">self</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">split_dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">del</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dy</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">with</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">enable_grad</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            y1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">requires_grad </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-7\">True</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            gy1 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-13\">self</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">g</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">(</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">y1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">set_rng</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-7\">True</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">**</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">g_args</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">autograd</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">backward</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">(</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">gy1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dy2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">with</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">no_grad</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            x2 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> y2 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">-</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> gy1</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">del</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> y2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> gy1</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            dx1 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dy1 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">+</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> y1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">grad</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">del</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dy1</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            y1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">grad </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-7\">None</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">with</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">enable_grad</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            x2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">requires_grad </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-7\">True</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            fx2 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-13\">self</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">f</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">(</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">x2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">set_rng</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-7\">True</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">**</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">f_args</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">autograd</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">backward</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">(</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">fx2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dx1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">with</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">no_grad</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">():</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            x1 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> y1 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">-</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> fx2</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">del</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> y1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> fx2</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            dx2 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dy2 </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">+</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> x2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">grad</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">del</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dy2</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            x2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">grad </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-7\">None</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            x </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">cat</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">([</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">x1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> x2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">detach</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">()],</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-13\">self</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">split_dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">            dx </span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> torch</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">cat</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">([</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">dx1</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dx2</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">],</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> </span><span class=\"grvsc-tZ0ymb-7 grvsc-tuw09S-3\">dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-15\">=</span><span class=\"grvsc-tZ0ymb-5 grvsc-tuw09S-13\">self</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">.</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">split_dim</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\">        </span><span class=\"grvsc-tZ0ymb-10 grvsc-tuw09S-11\">return</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> x</span><span class=\"grvsc-tZ0ymb-6 grvsc-tuw09S-1\">,</span><span class=\"grvsc-tZ0ymb-1 grvsc-tuw09S-1\"> dx</span></span></span></code></pre>\n<p>The lines such as <code>del y</code> and <code>del dy</code> were probably added to address OOM issues. The authors switched between <code>x2.detach()</code>, <code>with torch.no_grad()</code> and <code>with torch.enable_grad()</code>, and combined the results. This was what the authors meant by ”[saving] the activations that are expensive to compute” during the backward pass.</p>\n<p>The rest of the paper focuses on analyzing model peroformance on standard metrics and benchmarks in NLP. It was trained on Meta’s GPU cluster for 21 days. Essentially, in order to improve model performance during training and inference, it requires a combination of mathematical and engineering rigor.</p>\n<p>The quoted text are from LLaMA: Open and Efficient Foundation Language Models by Touvron et al, <a href=\"https://arxiv.org/abs/2302.13971\">https://arxiv.org/abs/2302.13971</a></p>\n<p>Code: <a href=\"https://github.com/facebookresearch/xformers\">https://github.com/facebookresearch/xformers</a></p>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .quiet-light { background-color: #F5F5F5; }\n  .quiet-light .grvsc-tZ0ymb-i { font-style: italic; }\n  .quiet-light .grvsc-tZ0ymb-b { font-weight: bold; }\n  .quiet-light .grvsc-tZ0ymb-1 { color: #333333; }\n  .quiet-light .grvsc-tZ0ymb-7 { color: #7A3E9D; }\n  .quiet-light .grvsc-tZ0ymb-9 { color: #AA3731; }\n  .quiet-light .grvsc-tZ0ymb-6 { color: #777777; }\n  .quiet-light .grvsc-tZ0ymb-3 { color: #AAAAAA; }\n  .quiet-light .grvsc-tZ0ymb-5 { color: #9C5D27; }\n  .quiet-light .grvsc-tZ0ymb-10 { color: #4B69C6; }\n  .quiet-light .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(0, 0, 0, 0.05));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(0, 0, 0, 0.2));\n  }\n  div#dark .grvsc-ps-tuw09S {\n    background-color: #1e1e1e;\n    color: #c5c8c6;\n  }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-1 { color: #C5C8C6FF; }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-11 { color: #9872A2; }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-10 { color: #CE6700; }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-3 { color: #6089B4; }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-15 { color: #676867; }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-4 { color: #9A9B99; }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-13 { color: #C7444A; }\n  div#dark .grvsc-ps-tuw09S .grvsc-tuw09S-7 { color: #408080; }\n  div#dark .grvsc-ps-tuw09S .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));\n  }\n</style>","frontmatter":{"title":"What MLEs can learn from the LLaMA Paper About Efficient LLM Models","category":["machine learning"],"date":"17 May 2024","coverImage":{"publicURL":"/static/111d870da93c223a5e42711acee9e9ce/math.jpg","childImageSharp":{"sizes":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAwAB/8QAFQEBAQAAAAAAAAAAAAAAAAAAAgH/2gAMAwEAAhADEAAAAR0op4aL/8QAGhAAAgIDAAAAAAAAAAAAAAAAAAECQhEjMf/aAAgBAQABBQLGuXGitT//xAAVEQEBAAAAAAAAAAAAAAAAAAAAEf/aAAgBAwEBPwFX/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFxAAAwEAAAAAAAAAAAAAAAAAAAEgMf/aAAgBAQAGPwIWQj//xAAZEAADAAMAAAAAAAAAAAAAAAAAATEhQXH/2gAIAQEAAT8heGCuNGaI3NOjnB//2gAMAwEAAgADAAAAEFTP/8QAGBEAAgMAAAAAAAAAAAAAAAAAACEBEYH/2gAIAQMBAT8QtYSx/8QAFxEAAwEAAAAAAAAAAAAAAAAAABEhgf/aAAgBAgEBPxBXRH//xAAbEAADAAIDAAAAAAAAAAAAAAAAARExoUFxsf/aAAgBAQABPxB1J2o5eTyJLatcti2rwZdIf//Z","aspectRatio":2.168141592920354,"src":"/static/111d870da93c223a5e42711acee9e9ce/c3638/math.jpg","srcSet":"/static/111d870da93c223a5e42711acee9e9ce/c3816/math.jpg 245w,\n/static/111d870da93c223a5e42711acee9e9ce/4dc99/math.jpg 490w,\n/static/111d870da93c223a5e42711acee9e9ce/c3638/math.jpg 600w","sizes":"(max-width: 600px) 100vw, 600px"}}}},"fields":{"slug":"/margin-note-llama/","readingTime":{"text":"6 min read"}}},"previous":{"fields":{"slug":"/neural-net-raw/"},"frontmatter":{"title":"A World without Tensorflow or Pytorch"}},"next":null,"webmention":{"nodes":[]}},"pageContext":{"slug":"/margin-note-llama/","previousPostId":"fbb4340d-6a85-5652-b727-d78997abec4b","nextPostId":null,"permalink":"https://violetguos.github.ioblog/margin-note-llama/"}},"staticQueryHashes":["2652830850","2841359383","287504094","3255793931"]}